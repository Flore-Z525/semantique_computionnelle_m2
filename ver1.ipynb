{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 简单显示多个nom在corpus里的Polysemy score",
   "id": "cf8d03802d33c8f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:42:08.376243Z",
     "start_time": "2025-01-09T16:42:08.309821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "import numpy as np\n",
    "import re\n"
   ],
   "id": "e6a5173928cdaaf4",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:42:08.400748Z",
     "start_time": "2025-01-09T16:42:08.391310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"简化的预处理函数\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n"
   ],
   "id": "8530f879c59aff1f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:42:08.518257Z",
     "start_time": "2025-01-09T16:42:08.421853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_word_embeddings(texts, word, tokenizer, model, batch_size=8):\n",
    "    \"\"\"获取特定词在所有上下文中的嵌入向量\"\"\"\n",
    "    word_embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "\n",
    "        # 对批次进行编码\n",
    "        inputs = tokenizer(batch_texts,\n",
    "                         padding=True,\n",
    "                         truncation=True,\n",
    "                         max_length=512,\n",
    "                         return_tensors=\"pt\")\n",
    "\n",
    "        # 获取每个句子中目标词的位置\n",
    "        word_ids = []\n",
    "        for text in batch_texts:\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            # 找出目标词的位置（考虑分词后可能的变化）\n",
    "            word_positions = []\n",
    "            for i, token in enumerate(tokens):\n",
    "                if word in token:\n",
    "                    word_positions.append(i + 1)  # +1 是因为[CLS]标记\n",
    "            if word_positions:\n",
    "                word_ids.append(word_positions[0])\n",
    "            else:\n",
    "                word_ids.append(None)\n",
    "\n",
    "        # 获取embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "\n",
    "            # 提取目标词的embeddings\n",
    "            for idx, word_id in enumerate(word_ids):\n",
    "                if word_id is not None:\n",
    "                    word_embeddings.append(hidden_states[idx, word_id].numpy())\n",
    "\n",
    "    return word_embeddings\n"
   ],
   "id": "8e9d2c51747bbe97",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:42:08.538870Z",
     "start_time": "2025-01-09T16:42:08.528553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_single_word(word, df, sample_size=100):\n",
    "    \"\"\"分析单个词的多义性\"\"\"\n",
    "    # 初始化模型和分词器\n",
    "    tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "    model = CamembertModel.from_pretrained('camembert-base')\n",
    "    model.eval()\n",
    "\n",
    "    # 筛选包含目标词的句子\n",
    "    relevant_texts = df[df['review'].str.contains(word, case=False, na=False, regex=False)]\n",
    "\n",
    "    if len(relevant_texts) == 0:\n",
    "        print(f\"No occurrences found for word: {word}\")\n",
    "        return None\n",
    "\n",
    "    # 如果句子太多，随机抽样\n",
    "    if len(relevant_texts) > sample_size:\n",
    "        relevant_texts = relevant_texts.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    print(f\"\\nAnalyzing word '{word}' in {len(relevant_texts)} contexts...\")\n",
    "\n",
    "    # 预处理文本\n",
    "    processed_texts = [preprocess_text(text) for text in relevant_texts['review']]\n",
    "\n",
    "    # 获取词的所有embeddings\n",
    "    word_embeddings = get_word_embeddings(processed_texts, word, tokenizer, model)\n",
    "\n",
    "    # 确保我们有足够的embeddings来计算多义性\n",
    "    if len(word_embeddings) >= 2:\n",
    "        # 转换为numpy数组\n",
    "        embeddings_array = np.array(word_embeddings)\n",
    "\n",
    "        # 计算余弦相似度矩阵\n",
    "        norm = np.linalg.norm(embeddings_array, axis=1, keepdims=True)\n",
    "        normalized_embeddings = embeddings_array / norm\n",
    "        similarity_matrix = np.dot(normalized_embeddings, normalized_embeddings.T)\n",
    "\n",
    "        # 获取上三角矩阵的值（不包括对角线）\n",
    "        upper_tri = similarity_matrix[np.triu_indices(len(similarity_matrix), k=1)]\n",
    "\n",
    "        # 计算标准差\n",
    "        polysemy_score = np.std(upper_tri)\n",
    "\n",
    "        return {\n",
    "            'word': word,\n",
    "            'occurrences': len(word_embeddings),\n",
    "            'polysemy_score': polysemy_score\n",
    "        }\n",
    "    return None\n"
   ],
   "id": "f9000805c694874a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:42:08.547556Z",
     "start_time": "2025-01-09T16:42:08.542984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 主函数\n",
    "def quick_polysemy_analysis(file_path, target_words, sample_size=100):\n",
    "    \"\"\"主分析函数\"\"\"\n",
    "    # 读取数据\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 分析每个词\n",
    "    results = []\n",
    "    for word in target_words:\n",
    "        result = analyze_single_word(word, df, sample_size)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            print(f\"Word: {result['word']}\")\n",
    "            print(f\"Occurrences: {result['occurrences']}\")\n",
    "            print(f\"Polysemy score: {result['polysemy_score']:.4f}\\n\")\n",
    "\n",
    "    return results\n"
   ],
   "id": "423b936225e8f73e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:43:52.544169Z",
     "start_time": "2025-01-09T16:42:08.572280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用示例\n",
    "file_path = 'test.csv'  # 或者您的文件路径\n",
    "target_words = ['film', 'histoire', 'bureau', 'opéra', 'rouge', 'carte', 'règle', 'avocat']\n",
    "results = quick_polysemy_analysis(file_path, target_words, sample_size=50)"
   ],
   "id": "b1cb3f8634a150b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "\n",
      "Analyzing word 'film' in 50 contexts...\n",
      "Word: film\n",
      "Occurrences: 50\n",
      "Polysemy score: 0.0931\n",
      "\n",
      "\n",
      "Analyzing word 'histoire' in 50 contexts...\n",
      "Word: histoire\n",
      "Occurrences: 50\n",
      "Polysemy score: 0.0802\n",
      "\n",
      "\n",
      "Analyzing word 'bureau' in 37 contexts...\n",
      "Word: bureau\n",
      "Occurrences: 37\n",
      "Polysemy score: 0.1691\n",
      "\n",
      "\n",
      "Analyzing word 'opéra' in 50 contexts...\n",
      "Word: opéra\n",
      "Occurrences: 50\n",
      "Polysemy score: 0.1950\n",
      "\n",
      "\n",
      "Analyzing word 'rouge' in 50 contexts...\n",
      "Word: rouge\n",
      "Occurrences: 50\n",
      "Polysemy score: 0.1403\n",
      "\n",
      "\n",
      "Analyzing word 'carte' in 50 contexts...\n",
      "Word: carte\n",
      "Occurrences: 44\n",
      "Polysemy score: 0.1788\n",
      "\n",
      "\n",
      "Analyzing word 'règle' in 50 contexts...\n",
      "Word: règle\n",
      "Occurrences: 50\n",
      "Polysemy score: 0.1765\n",
      "\n",
      "\n",
      "Analyzing word 'avocat' in 48 contexts...\n",
      "Word: avocat\n",
      "Occurrences: 48\n",
      "Polysemy score: 0.1441\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T16:43:52.624309Z",
     "start_time": "2025-01-09T16:43:52.621726Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e40a3608e1e44125",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
