{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 显示nom(s)的Polysemy score、在原文件的第几个review出现、对应的word embedding\n",
    "\n",
    "#### 问题：比如目标词为beau的时候，不含beau但含beaufitude的review也会被找出（不过beau不是作业要求的名词/动词）"
   ],
   "id": "9061b4df51dd2b98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T15:59:01.366604Z",
     "start_time": "2025-01-09T15:58:48.314401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import CamembertTokenizer, CamembertModel\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def preprocess_and_embed(texts, ids, word, tokenizer, model, batch_size=8):\n",
    "    \"\"\"预处理文本并获取目标词嵌入\"\"\"\n",
    "    word_embeddings = []\n",
    "    review_embeddings = []  # 存储每个review的embedding信息\n",
    "\n",
    "    # 对批次进行编码\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        batch_ids = ids[i:i + batch_size]  # 对应的id\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "        # 获取每个句子中目标词的位置\n",
    "        word_ids = [next((i+1 for i, token in enumerate(tokenizer.tokenize(text)) if word in token), None) for text in batch_texts]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "\n",
    "            # 提取目标词的embeddings并记录索引\n",
    "            for idx, word_id in enumerate(word_ids):\n",
    "                if word_id is not None:\n",
    "                    word_embeddings.append(hidden_states[idx, word_id].numpy())\n",
    "                    review_embeddings.append({'id': batch_ids[idx], 'embedding': hidden_states[idx, word_id].numpy()})\n",
    "\n",
    "    return word_embeddings, review_embeddings\n",
    "\n",
    "def analyze_word(word, df, sample_size=100):\n",
    "    \"\"\"分析单个词的多义性\"\"\"\n",
    "    tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "    model = CamembertModel.from_pretrained('camembert-base')\n",
    "    model.eval()\n",
    "\n",
    "    relevant_texts = df[df['review'].str.contains(word, case=False, na=False, regex=False)]\n",
    "    if relevant_texts.empty:\n",
    "        print(f\"No occurrences found for word: {word}\")\n",
    "        return None\n",
    "\n",
    "    relevant_texts = relevant_texts.sample(n=min(len(relevant_texts), sample_size), random_state=42)\n",
    "\n",
    "    # 获取对应的id和预处理文本\n",
    "    ids = relevant_texts.iloc[:, 0].values  # 第一列是id\n",
    "    processed_texts = [re.sub(r'[^\\w\\s]', ' ', str(text).lower()).strip() for text in relevant_texts['review']]\n",
    "\n",
    "    word_embeddings, review_embeddings = preprocess_and_embed(processed_texts, ids, word, tokenizer, model)\n",
    "\n",
    "    if len(word_embeddings) < 2:\n",
    "        return None\n",
    "\n",
    "    # 计算余弦相似度矩阵并得到多义性分数\n",
    "    embeddings_array = np.array(word_embeddings)\n",
    "    norm = np.linalg.norm(embeddings_array, axis=1, keepdims=True)\n",
    "    similarity_matrix = np.dot(embeddings_array / norm, (embeddings_array / norm).T)\n",
    "\n",
    "    polysemy_score = np.std(similarity_matrix[np.triu_indices(len(similarity_matrix), k=1)])\n",
    "\n",
    "    return {\n",
    "        'word': word,\n",
    "        'occurrences': len(word_embeddings),\n",
    "        'polysemy_score': polysemy_score,\n",
    "        'review_embeddings': review_embeddings  # 返回每个review的目标词嵌入和对应的id\n",
    "    }\n",
    "\n",
    "def quick_polysemy_analysis(file_path, target_words, sample_size=100):\n",
    "    \"\"\"主分析函数\"\"\"\n",
    "    df = pd.read_csv(file_path, header=None, names=['id', 'film-url', 'review', 'polarity'])\n",
    "    results = [analyze_word(word, df, sample_size) for word in target_words if analyze_word(word, df, sample_size)]\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Word: {result['word']}\")\n",
    "        print(f\"Occurrences: {result['occurrences']}\")\n",
    "        print(f\"Polysemy score: {result['polysemy_score']:.4f}\\n\")\n",
    "\n",
    "        # 输出每个review的目标词嵌入及其对应的id\n",
    "        for review in result['review_embeddings']:\n",
    "            print(f\"Review ID {review['id']}: {review['embedding'][:5]}...\")  # 显示嵌入的前5个数值，避免输出过长\n",
    "\n",
    "    return results\n",
    "\n",
    "# 使用示例\n",
    "file_path = 'test.csv'\n",
    "target_words = ['histoire']\n",
    "results = quick_polysemy_analysis(file_path, target_words, sample_size=20)\n"
   ],
   "id": "93db86faeb4e0767",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: histoire\n",
      "Occurrences: 20\n",
      "Polysemy score: 0.0814\n",
      "\n",
      "Review ID 5268.0: [ 0.09102798  0.16917096 -0.0473657   0.08430825 -0.02601945]...\n",
      "Review ID 16712.0: [ 0.08545251 -0.19848987  0.1817712   0.09085849 -0.03145574]...\n",
      "Review ID 14784.0: [ 0.00460607  0.38902065  0.07689978  0.0377639  -0.07112113]...\n",
      "Review ID 8330.0: [ 0.04240461  0.29707024  0.04431971 -0.05684883 -0.10839397]...\n",
      "Review ID 10590.0: [ 0.04102797 -0.01848955  0.1679564   0.12878132 -0.10983775]...\n",
      "Review ID 10994.0: [ 0.05358908  0.08450424  0.25529757 -0.0101518  -0.16198653]...\n",
      "Review ID 13438.0: [ 0.04295095  0.07399024  0.07357954  0.02631695 -0.08958986]...\n",
      "Review ID 3650.0: [ 0.09568378  0.07725815  0.13869886  0.12635812 -0.07432344]...\n",
      "Review ID 19938.0: [ 0.01281912  0.34325552  0.05590718 -0.01954528 -0.01867477]...\n",
      "Review ID 1302.0: [ 0.03350243  0.07806947 -0.03638034 -0.00755402 -0.07943187]...\n",
      "Review ID 10896.0: [ 0.03729968  0.30961126 -0.13613316  0.02256236 -0.08108057]...\n",
      "Review ID 4412.0: [-0.04707182  0.4662896   0.1031778   0.06533112  0.02314021]...\n",
      "Review ID 19891.0: [ 0.08673216  0.08554965  0.1282261  -0.06058402 -0.14421146]...\n",
      "Review ID 14854.0: [ 0.08331009  0.11896989  0.05283698  0.03020684 -0.08864042]...\n",
      "Review ID 19875.0: [ 0.06448698  0.17423409  0.24544072 -0.03564861 -0.12117726]...\n",
      "Review ID 5329.0: [ 0.06639864  0.1636317   0.03286015  0.04152388 -0.02467389]...\n",
      "Review ID 113.0: [ 0.05510858  0.15267304 -0.0317846   0.10668147 -0.06761174]...\n",
      "Review ID 5062.0: [-0.04084893  0.19968462  0.2778696  -0.10433684 -0.16798341]...\n",
      "Review ID 9709.0: [-0.0319621   0.0258816   0.10503037  0.02085366  0.05239328]...\n",
      "Review ID 4556.0: [ 0.11932746  0.06813559 -0.03358129  0.15413189 -0.04499959]...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5152cd57082f95d9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
